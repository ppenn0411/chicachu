# -*- coding: utf-8 -*-
"""
LSTM ëª¨ë¸ í•™ìŠµ + LOSO í‰ê°€ (í”„ë¡œì íŠ¸ í´ë” êµ¬ì¡° ë° ì‹œê°„ ë¡œê¹… ê¸°ëŠ¥ ë°˜ì˜)
- ì…ë ¥: artifacts/<project_tag>/<build_tag> ì˜ ë°ì´í„°
- TCNê³¼ ë™ì¼í•œ ë©€í‹°íƒœìŠ¤í¬, LOSO í‰ê°€ ë¡œì§ ì‚¬ìš©
- Zero-fillëœ ë°ì´í„°ë¥¼ ë¬´ì‹œí•˜ê¸° ìœ„í•œ Masking ë ˆì´ì–´ ì¶”ê°€
- ì¶œë ¥: runs/<project_tag>/<build_tag>/lstm_<timestamp>/... ì— ê²°ê³¼ ì €ì¥
"""

import os
import json
import argparse
import time
import numpy as np
import tensorflow as tf
from tensorflow.keras import layers, models
from sklearn.metrics import classification_report
from sklearn.model_selection import train_test_split

# ----- ë°ì´í„° ë¡œë”© ë° LOSO ë¶„í•  í•¨ìˆ˜ (TCN ìŠ¤í¬ë¦½íŠ¸ì™€ ë™ì¼) -----
def load_arrays(root_path, build_tag):
    """artifacts/<project_tag>/<build_tag> ì—ì„œ ë°ì´í„° ë¡œë“œ"""
    X = np.load(os.path.join(root_path, f'X_data_mt_{build_tag}.npy'))
    y_s = np.load(os.path.join(root_path, f'y_surface_mt_{build_tag}.npy'))
    y_h = np.load(os.path.join(root_path, f'y_horizontal_mt_{build_tag}.npy'))
    y_v = np.load(os.path.join(root_path, f'y_vertical_mt_{build_tag}.npy'))
    m_v = np.load(os.path.join(root_path, f'mask_vertical_mt_{build_tag}.npy'))
    groups = np.load(os.path.join(root_path, f'groups_mt_{build_tag}.npy'))
    meta = json.load(open(os.path.join(root_path, f'encoder_meta_{build_tag}.json'),'r',encoding='utf-8'))
    return X, y_s, y_h, y_v, m_v, groups, meta

def make_loso_splits(groups):
    """ì‚¬ëŒ(group)ë³„ë¡œ LOSO êµì°¨ ê²€ì¦ì„ ìœ„í•œ ë°ì´í„° ì¸ë±ìŠ¤ë¥¼ ë¶„í• í•©ë‹ˆë‹¤."""
    persons = sorted(list(set(groups.tolist())))
    for p in persons:
        test_idx = (groups == p)
        train_idx = ~test_idx
        yield p, train_idx, test_idx

# -------------------- ëª¨ë¸ êµ¬ì¶• í•¨ìˆ˜ --------------------
def build_mt_lstm(input_shape: tuple, n_surface=3, n_h=3, n_v=2):
    """ë©€í‹°íƒœìŠ¤í¬ LSTM ëª¨ë¸ì„ êµ¬ì¶•í•©ë‹ˆë‹¤."""
    inp = layers.Input(shape=input_shape)
    
    # Masking ë ˆì´ì–´: ì…ë ¥ê°’ ì¤‘ ëª¨ë“  í”¼ì²˜ê°€ 0.0ì¸ íƒ€ì„ìŠ¤í…ì€ ê³„ì‚°ì—ì„œ ì œì™¸ì‹œí‚µë‹ˆë‹¤.
    # Zero-fillëœ ì† ë¯¸ê²€ì¶œ í”„ë ˆì„ì„ ëª¨ë¸ì´ ë¬´ì‹œí•˜ë„ë¡ í•˜ëŠ” íš¨ê³¼ê°€ ìˆìŠµë‹ˆë‹¤.
    x = layers.Masking(mask_value=0.0)(inp)
    
    # LSTM ë ˆì´ì–´ë¥¼ 2ê²¹ìœ¼ë¡œ ìŒ“ì•„ ì‹œê°„ì  íŒ¨í„´ì„ í•™ìŠµí•©ë‹ˆë‹¤.
    x = layers.LSTM(128, return_sequences=True)(x)
    x = layers.LSTM(128)(x)
    
    # ë©€í‹°íƒœìŠ¤í¬ ì¶œë ¥ì„ ìœ„í•œ Dense ë ˆì´ì–´ë“¤
    h = layers.Dense(128, activation='relu')(x)
    out_s = layers.Dense(n_surface, activation='softmax', name='surface')(h)
    out_h = layers.Dense(n_h, activation='softmax', name='horizontal')(h)
    out_v = layers.Dense(n_v, activation='softmax', name='vertical')(h)
    
    model = models.Model(inp, [out_s, out_h, out_v])
    model.compile(
        optimizer=tf.keras.optimizers.Adam(1e-3),
        loss={
            "surface": "sparse_categorical_crossentropy",
            "horizontal": "sparse_categorical_crossentropy",
            "vertical": "sparse_categorical_crossentropy"
        },
        metrics=["accuracy"]
    )
    return model

# -------------------- ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ --------------------
def main():
    ap = argparse.ArgumentParser(description="LSTM ëª¨ë¸ í•™ìŠµ ë° LOSO í‰ê°€ ìŠ¤í¬ë¦½íŠ¸")
    ap.add_argument('--project_tag', required=True, help='í”„ë¡œì íŠ¸ ë²„ì „ íƒœê·¸ (ì˜ˆ: v1_eyes)')
    ap.add_argument('--build_tag', required=True, help='ë°ì´í„°ì…‹ ë¹Œë“œ ë²„ì „ íƒœê·¸ (ì˜ˆ: base_sl15)')
    ap.add_argument('--epochs', type=int, default=80)
    ap.add_argument('--batch_size', type=int, default=64)
    args = ap.parse_args()

    # ê²½ë¡œ ì„¤ì •
    artifacts_root = os.path.join('artifacts', args.project_tag, args.build_tag)
    if not os.path.isdir(artifacts_root):
        raise FileNotFoundError(f"ì…ë ¥ ë°°ì—´ í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤: {artifacts_root}")

    timestamp = time.strftime('%Y%m%d_%H%M%S')
    runs_root = os.path.join('runs', args.project_tag, args.build_tag, f'lstm_{timestamp}')
    os.makedirs(runs_root, exist_ok=True)

    # ë°ì´í„° ë¡œë”©
    X, y_s, y_h, y_v, m_v, groups, meta = load_arrays(artifacts_root, args.build_tag)
    N, L, F = X.shape
    
    # ì „ì²´ ì‹¤í–‰ ì •ë³´ ì €ì¥ (manifest.json)
    with open(os.path.join(runs_root, 'manifest.json'), 'w', encoding='utf-8') as f:
        json.dump({
            'project_tag': args.project_tag, 'build_tag': args.build_tag, 'model_type': 'LSTM',
            'timestamp': timestamp, 'seq_len': int(L), 'feat_dim': int(F),
            'epochs': args.epochs, 'batch_size': args.batch_size,
            'artifacts_root': os.path.abspath(artifacts_root)
        }, f, ensure_ascii=False, indent=2)

    # LOSO êµì°¨ ê²€ì¦ ë£¨í”„
    for fold_i, (person, tr_idx, te_idx) in enumerate(make_loso_splits(groups), start=1):
        t_fold_start = time.time()

        fold_dir = os.path.join(runs_root, f'loso-{person}')
        for d in ['models', 'preds', 'metrics']:
            os.makedirs(os.path.join(fold_dir, d), exist_ok=True)

        print(f'\n=== FOLD {fold_i}/{len(set(groups))} | Testing on person={person} ===')

        # ë°ì´í„° ë¶„í• 
        Xtr, Xte = X[tr_idx], X[te_idx]
        ytr_s, yte_s = y_s[tr_idx], y_s[te_idx]
        ytr_h, yte_h = y_h[tr_idx], y_h[te_idx]
        ytr_v, yte_v = y_v[tr_idx], y_v[te_idx]
        mtr_v, mte_v = m_v[tr_idx], m_v[te_idx]
        ytr_v_eff = np.where(ytr_v < 0, 0, ytr_v)
        yte_v_eff = np.where(yte_v < 0, 0, yte_v)
        
        # ëª¨ë¸ ìƒì„± ë° í•™ìŠµ
        model = build_mt_lstm((L, F))
        cb = [
            tf.keras.callbacks.ModelCheckpoint(
                os.path.join(fold_dir, 'models', 'lstm_best_model.h5'),
                save_best_only=True, monitor='val_surface_accuracy', mode='max'),
            tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)
        ]

        model.fit(
            Xtr, [ytr_s, ytr_h, ytr_v_eff],
            validation_data=(Xte, [yte_s, yte_h, yte_v_eff], {"vertical": mte_v}),
            epochs=args.epochs, batch_size=args.batch_size,
            sample_weight={"surface": np.ones_like(ytr_s), "horizontal": np.ones_like(ytr_h), "vertical": mtr_v},
            callbacks=cb, verbose=2
        )

        # ì˜ˆì¸¡ ë° ê²°ê³¼ ì €ì¥
        yhat_s, yhat_h, yhat_v = model.predict(Xte, verbose=0)
        ypred_s, ypred_h, ypred_v = yhat_s.argmax(1), yhat_h.argmax(1), yhat_v.argmax(1)
        np.save(os.path.join(fold_dir, 'preds', 'y_true_surface.npy'), yte_s)
        np.save(os.path.join(fold_dir, 'preds', 'y_pred_surface.npy'), ypred_s)
        np.save(os.path.join(fold_dir, 'preds', 'y_true_horizontal.npy'), yte_h)
        np.save(os.path.join(fold_dir, 'preds', 'y_pred_horizontal.npy'), ypred_h)
        np.save(os.path.join(fold_dir, 'preds', 'y_true_vertical.npy'), yte_v)
        np.save(os.path.join(fold_dir, 'preds', 'y_pred_vertical.npy'), ypred_v)

        # ì„±ëŠ¥ ì§€í‘œ ê³„ì‚° ë° ì €ì¥
        metrics_dir = os.path.join(fold_dir, 'metrics')
        rep_s = classification_report(yte_s, ypred_s, output_dict=True, zero_division=0)
        rep_h = classification_report(yte_h, ypred_h, output_dict=True, zero_division=0)
        f1_metrics = {
            'surface': {'macro_f1': rep_s['macro avg']['f1-score']},
            'horizontal': {'macro_f1': rep_h['macro avg']['f1-score']}
        }
        if np.any(yte_v >= 0):
            mask = yte_v >= 0
            rep_v = classification_report(yte_v[mask], ypred_v[mask], output_dict=True, zero_division=0)
            f1_metrics['vertical'] = {'macro_f1': rep_v['macro avg']['f1-score']}
        
        with open(os.path.join(metrics_dir, 'f1.json'), 'w', encoding='utf-8') as f:
            json.dump(f1_metrics, f, ensure_ascii=False, indent=2)

        # Fold ì²˜ë¦¬ ì‹œê°„ ê¸°ë¡ ë° ì €ì¥
        fold_duration_sec = time.time() - t_fold_start
        with open(os.path.join(fold_dir, 'manifest.json'), 'w', encoding='utf-8') as f:
            json.dump({
                'person': person,
                'train_count': int(tr_idx.sum()),
                'test_count': int(te_idx.sum()),
                'duration_sec': fold_duration_sec
            }, f, ensure_ascii=False, indent=2)
            
        print(f"[INFO] Fold {person} complete in {fold_duration_sec:.2f}s. Val F1(surface): {f1_metrics['surface']['macro_f1']:.4f}")

    print('\nâœ… All folds finished for LSTM.')
    print(f'ğŸ“ Runs saved to: {runs_root}')

if __name__ == '__main__':
    main()
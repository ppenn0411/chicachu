# -*- coding: utf-8 -*-
"""
Random Forest ëª¨ë¸ í•™ìŠµ + LOSO í‰ê°€ (í”„ë¡œì íŠ¸ í´ë” êµ¬ì¡° ë° ì‹œê°„ ë¡œê¹… ê¸°ëŠ¥ ë°˜ì˜)
- ì…ë ¥: artifacts/<project_tag>/<build_tag> ì˜ ë°ì´í„°
- ì‹œê³„ì—´ ë°ì´í„°ë¥¼ í†µê³„ í”¼ì²˜ë¡œ ë³€í™˜í•˜ì—¬ 2D ë°ì´í„°ë¡œ ê°€ê³µ
- 3ê°œì˜ Taskì— ëŒ€í•´ 3ê°œì˜ ë…ë¦½ì ì¸ RF ëª¨ë¸ì„ í•™ìŠµ
- ì¶œë ¥: runs/<project_tag>/<build_tag>/rf_<timestamp>/... ì— ê²°ê³¼ ì €ì¥
"""

import os
import json
import argparse
import time
import numpy as np
import pickle
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import f1_score, classification_report

# ----- ë°ì´í„° ë¡œë”© ë° LOSO ë¶„í•  í•¨ìˆ˜ (TCN ìŠ¤í¬ë¦½íŠ¸ì™€ ë™ì¼) -----
def load_arrays(root_path, build_tag):
    """artifacts/<project_tag>/<build_tag> ì—ì„œ ë°ì´í„° ë¡œë“œ"""
    X = np.load(os.path.join(root_path, f'X_data_mt_{build_tag}.npy'))
    y_s = np.load(os.path.join(root_path, f'y_surface_mt_{build_tag}.npy'))
    y_h = np.load(os.path.join(root_path, f'y_horizontal_mt_{build_tag}.npy'))
    y_v = np.load(os.path.join(root_path, f'y_vertical_mt_{build_tag}.npy'))
    m_v = np.load(os.path.join(root_path, f'mask_vertical_mt_{build_tag}.npy'))
    groups = np.load(os.path.join(root_path, f'groups_mt_{build_tag}.npy'))
    meta = json.load(open(os.path.join(root_path, f'encoder_meta_{build_tag}.json'),'r',encoding='utf-8'))
    return X, y_s, y_h, y_v, m_v, groups, meta

def make_loso_splits(groups):
    """ì‚¬ëŒ(group)ë³„ë¡œ LOSO êµì°¨ ê²€ì¦ì„ ìœ„í•œ ë°ì´í„° ì¸ë±ìŠ¤ë¥¼ ë¶„í• í•©ë‹ˆë‹¤."""
    persons = sorted(list(set(groups.tolist())))
    for p in persons:
        test_idx = (groups == p)
        train_idx = ~test_idx
        yield p, train_idx, test_idx

# ----- í•µì‹¬: ì‹œê³„ì—´ ë°ì´í„°ë¥¼ 2D í†µê³„ í”¼ì²˜ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜ -----
def featurize_sequences(X: np.ndarray) -> np.ndarray:
    """ (N, L, F) -> (N, F*4) í˜•íƒœë¡œ ë³€í™˜. ê° í”¼ì²˜ì˜ í‰ê· , í‘œì¤€í¸ì°¨, ìµœì†Œ, ìµœëŒ€ê°’ì„ ê³„ì‚°. """
    if X.ndim != 3:
        raise ValueError("ì…ë ¥ ë°°ì—´ì€ 3ì°¨ì›ì´ì–´ì•¼ í•©ë‹ˆë‹¤ (N, L, F).")
    N, L, F = X.shape
    stat_features = np.zeros((N, F * 4), dtype=np.float32)
    for f_idx in range(F):
        stat_features[:, f_idx * 4 + 0] = np.mean(X[:, :, f_idx], axis=1)
        stat_features[:, f_idx * 4 + 1] = np.std(X[:, :, f_idx], axis=1)
        stat_features[:, f_idx * 4 + 2] = np.min(X[:, :, f_idx], axis=1)
        stat_features[:, f_idx * 4 + 3] = np.max(X[:, :, f_idx], axis=1)
    return stat_features

# -------------------- ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ --------------------
def main():
    ap = argparse.ArgumentParser(description="Random Forest ëª¨ë¸ í•™ìŠµ ë° LOSO í‰ê°€ ìŠ¤í¬ë¦½íŠ¸")
    ap.add_argument('--project_tag', required=True, help='í”„ë¡œì íŠ¸ ë²„ì „ íƒœê·¸ (ì˜ˆ: v1_eyes)')
    ap.add_argument('--build_tag', required=True, help='ë°ì´í„°ì…‹ ë¹Œë“œ ë²„ì „ íƒœê·¸ (ì˜ˆ: base_sl15)')
    ap.add_argument('--n_estimators', type=int, default=200, help="ëœë¤ í¬ë ˆìŠ¤íŠ¸ì˜ íŠ¸ë¦¬ ê°œìˆ˜")
    ap.add_argument('--max_depth', type=int, default=15, help="íŠ¸ë¦¬ì˜ ìµœëŒ€ ê¹Šì´")
    args = ap.parse_args()

    # ê²½ë¡œ ì„¤ì •
    artifacts_root = os.path.join('artifacts', args.project_tag, args.build_tag)
    if not os.path.isdir(artifacts_root):
        raise FileNotFoundError(f"ì…ë ¥ ë°°ì—´ í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤: {artifacts_root}")

    timestamp = time.strftime('%Y%m%d_%H%M%S')
    runs_root = os.path.join('runs', args.project_tag, args.build_tag, f'rf_{timestamp}')
    os.makedirs(runs_root, exist_ok=True)
    
    # ë°ì´í„° ë¡œë”© ë° 2D í”¼ì²˜ë¡œ ê°€ê³µ
    X_seq, y_s, y_h, y_v, m_v, groups, meta = load_arrays(artifacts_root, args.build_tag)
    print(f"[INFO] Original sequence shape: {X_seq.shape}")
    X_flat = featurize_sequences(X_seq)
    print(f"[INFO] Featurized flat shape: {X_flat.shape}")
    
    # ì „ì²´ ì‹¤í–‰ ì •ë³´ ì €ì¥ (manifest.json)
    with open(os.path.join(runs_root, 'manifest.json'), 'w', encoding='utf-8') as f:
        json.dump({
            'project_tag': args.project_tag, 'build_tag': args.build_tag, 'model_type': 'RandomForest',
            'timestamp': timestamp, 'n_estimators': args.n_estimators, 'max_depth': args.max_depth,
            'artifacts_root': os.path.abspath(artifacts_root)
        }, f, ensure_ascii=False, indent=2)

    # LOSO êµì°¨ ê²€ì¦ ë£¨í”„
    for fold_i, (person, tr_idx, te_idx) in enumerate(make_loso_splits(groups), start=1):
        t_fold_start = time.time()

        fold_dir = os.path.join(runs_root, f'loso-{person}')
        for d in ['models', 'preds', 'metrics']:
            os.makedirs(os.path.join(fold_dir, d), exist_ok=True)
        print(f'\n=== FOLD {fold_i}/{len(set(groups))} | Testing on person={person} ===')

        Xtr, Xte = X_flat[tr_idx], X_flat[te_idx]
        
        # --- Task 1: Surface ---
        ytr_s, yte_s = y_s[tr_idx], y_s[te_idx]
        print("[INFO] Training 'surface' model...")
        model_s = RandomForestClassifier(n_estimators=args.n_estimators, max_depth=args.max_depth, random_state=42, n_jobs=-1)
        model_s.fit(Xtr, ytr_s)
        ypred_s = model_s.predict(Xte)
        
        # --- Task 2: Horizontal ---
        ytr_h, yte_h = y_h[tr_idx], y_h[te_idx]
        print("[INFO] Training 'horizontal' model...")
        model_h = RandomForestClassifier(n_estimators=args.n_estimators, max_depth=args.max_depth, random_state=42, n_jobs=-1)
        model_h.fit(Xtr, ytr_h)
        ypred_h = model_h.predict(Xte)
        
        # --- Task 3: Vertical (ë§ˆìŠ¤í¬ê°€ 1ì¸ ë°ì´í„°ë§Œ ì‚¬ìš©) ---
        mtr_v, mte_v = m_v[tr_idx], m_v[te_idx]
        ytr_v, yte_v = y_v[tr_idx], y_v[te_idx]
        print("[INFO] Training 'vertical' model...")
        model_v = RandomForestClassifier(n_estimators=args.n_estimators, max_depth=args.max_depth, random_state=42, n_jobs=-1)
        if np.any(mtr_v == 1):
            model_v.fit(Xtr[mtr_v == 1], ytr_v[mtr_v == 1])
        ypred_v = np.full_like(yte_v, -1)
        if np.any(mte_v == 1) and hasattr(model_v, 'classes_'):
            ypred_v[mte_v == 1] = model_v.predict(Xte[mte_v == 1])

        # --- [ìƒëµë˜ì§€ ì•Šì€ ë¶€ë¶„] ê²°ê³¼ ì €ì¥ ---
        # ëª¨ë¸ ì €ì¥
        pickle.dump(model_s, open(os.path.join(fold_dir, 'models', 'rf_surface.pkl'), 'wb'))
        pickle.dump(model_h, open(os.path.join(fold_dir, 'models', 'rf_horizontal.pkl'), 'wb'))
        if hasattr(model_v, 'classes_'):
             pickle.dump(model_v, open(os.path.join(fold_dir, 'models', 'rf_vertical.pkl'), 'wb'))
        
        # ì˜ˆì¸¡ ë° ì •ë‹µ ì €ì¥
        preds_dir = os.path.join(fold_dir, 'preds')
        np.save(os.path.join(preds_dir, 'y_true_surface.npy'), yte_s)
        np.save(os.path.join(preds_dir, 'y_pred_surface.npy'), ypred_s)
        np.save(os.path.join(preds_dir, 'y_true_horizontal.npy'), yte_h)
        np.save(os.path.join(preds_dir, 'y_pred_horizontal.npy'), ypred_h)
        np.save(os.path.join(preds_dir, 'y_true_vertical.npy'), yte_v)
        np.save(os.path.join(preds_dir, 'y_pred_vertical.npy'), ypred_v)

        # ì„±ëŠ¥ ì§€í‘œ ì €ì¥
        metrics_dir = os.path.join(fold_dir, 'metrics')
        rep_s = classification_report(yte_s, ypred_s, output_dict=True, zero_division=0)
        rep_h = classification_report(yte_h, ypred_h, output_dict=True, zero_division=0)
        f1_metrics = {
            'surface': {'macro_f1': rep_s['macro avg']['f1-score']},
            'horizontal': {'macro_f1': rep_h['macro avg']['f1-score']}
        }
        if np.any(mte_v == 1):
             rep_v = classification_report(yte_v[mte_v == 1], ypred_v[mte_v == 1], output_dict=True, zero_division=0)
             f1_metrics['vertical'] = {'macro_f1': rep_v['macro avg']['f1-score']}
        
        with open(os.path.join(metrics_dir, 'f1.json'), 'w', encoding='utf-8') as f:
            json.dump(f1_metrics, f, ensure_ascii=False, indent=2)

        # Fold ì²˜ë¦¬ ì‹œê°„ ê¸°ë¡ ë° ì €ì¥
        fold_duration_sec = time.time() - t_fold_start
        with open(os.path.join(fold_dir, 'manifest.json'), 'w', encoding='utf-8') as f:
            json.dump({
                'person': person,
                'train_count': int(tr_idx.sum()),
                'test_count': int(te_idx.sum()),
                'duration_sec': fold_duration_sec
            }, f, ensure_ascii=False, indent=2)

        print(f"[INFO] Fold {person} complete in {fold_duration_sec:.2f}s. Val F1(surface): {f1_metrics['surface']['macro_f1']:.4f}")

    print('\nâœ… All folds finished for Random Forest.')
    print(f'ğŸ“ Runs saved to: {runs_root}')

if __name__ == '__main__':
    main()
# -*- coding: utf-8 -*-
"""
Transformer ëª¨ë¸ í•™ìŠµ + LOSO í‰ê°€ (í”„ë¡œì íŠ¸ í´ë” êµ¬ì¡° ë° ì‹œê°„ ë¡œê¹… ê¸°ëŠ¥ ë°˜ì˜)
- ì…ë ¥: artifacts/<project_tag>/<build_tag> ì˜ ë°ì´í„°
- Self-Attention ê¸°ë°˜ì˜ Transformer Encoderë¥¼ ë°±ë³¸ìœ¼ë¡œ ì‚¬ìš©
- ì¶œë ¥: runs/<project_tag>/<build_tag>/transformer_<timestamp>/... ì— ê²°ê³¼ ì €ì¥
"""
import os
import json
import argparse
import time
import numpy as np
import tensorflow as tf
from tensorflow.keras import layers, models
from sklearn.metrics import classification_report

# ----- ë°ì´í„° ë¡œë”© ë° LOSO ë¶„í•  í•¨ìˆ˜ (TCN ìŠ¤í¬ë¦½íŠ¸ì™€ ë™ì¼) -----
def load_arrays(root_path, build_tag):
    """artifacts/<project_tag>/<build_tag> ì—ì„œ ë°ì´í„° ë¡œë“œ"""
    X = np.load(os.path.join(root_path, f'X_data_mt_{build_tag}.npy'))
    y_s = np.load(os.path.join(root_path, f'y_surface_mt_{build_tag}.npy'))
    y_h = np.load(os.path.join(root_path, f'y_horizontal_mt_{build_tag}.npy'))
    y_v = np.load(os.path.join(root_path, f'y_vertical_mt_{build_tag}.npy'))
    m_v = np.load(os.path.join(root_path, f'mask_vertical_mt_{build_tag}.npy'))
    groups = np.load(os.path.join(root_path, f'groups_mt_{build_tag}.npy'))
    meta = json.load(open(os.path.join(root_path, f'encoder_meta_{build_tag}.json'),'r',encoding='utf-8'))
    return X, y_s, y_h, y_v, m_v, groups, meta

def make_loso_splits(groups):
    """ì‚¬ëŒ(group)ë³„ë¡œ LOSO êµì°¨ ê²€ì¦ì„ ìœ„í•œ ë°ì´í„° ì¸ë±ìŠ¤ë¥¼ ë¶„í• í•©ë‹ˆë‹¤."""
    persons = sorted(list(set(groups.tolist())))
    for p in persons:
        test_idx = (groups == p)
        train_idx = ~test_idx
        yield p, train_idx, test_idx

# -------------------- Transformer ëª¨ë¸ êµ¬ì¶• í•¨ìˆ˜ --------------------
class TransformerEncoder(layers.Layer):
    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):
        super(TransformerEncoder, self).__init__()
        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)
        self.ffn = models.Sequential(
            [layers.Dense(ff_dim, activation="relu"), layers.Dense(embed_dim),]
        )
        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)
        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)
        self.dropout1 = layers.Dropout(rate)
        self.dropout2 = layers.Dropout(rate)

    def call(self, inputs, training):
        attn_output = self.att(inputs, inputs)
        attn_output = self.dropout1(attn_output, training=training)
        out1 = self.layernorm1(inputs + attn_output)
        ffn_output = self.ffn(out1)
        ffn_output = self.dropout2(ffn_output, training=training)
        return self.layernorm2(out1 + ffn_output)

class PositionalEncoding(layers.Layer):
    def __init__(self, position, d_model):
        super(PositionalEncoding, self).__init__()
        self.pos_encoding = self.positional_encoding(position, d_model)

    def get_angles(self, position, i, d_model):
        angles = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))
        return position * angles

    def positional_encoding(self, position, d_model):
        angle_rads = self.get_angles(
            np.arange(position)[:, np.newaxis], np.arange(d_model)[np.newaxis, :], d_model
        )
        angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])
        angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])
        pos_encoding = angle_rads[np.newaxis, ...]
        return tf.cast(pos_encoding, dtype=tf.float32)

    def call(self, inputs):
        return inputs + self.pos_encoding[:, : tf.shape(inputs)[1], :]

def build_mt_transformer(input_shape, n_surface=3, n_h=3, n_v=2, num_heads=4, ff_dim=128, num_blocks=2):
    """ë©€í‹°íƒœìŠ¤í¬ Transformer ëª¨ë¸ì„ êµ¬ì¶•í•©ë‹ˆë‹¤."""
    seq_len, feat_dim = input_shape
    embed_dim = feat_dim
    inp = layers.Input(shape=input_shape)
    x = PositionalEncoding(seq_len, embed_dim)(inp)
    for _ in range(num_blocks):
        x = TransformerEncoder(embed_dim, num_heads, ff_dim)(x)
    x = layers.GlobalAveragePooling1D()(x)
    h = layers.Dense(128, activation='relu')(x)
    out_s = layers.Dense(n_surface, activation='softmax', name='surface')(h)
    out_h = layers.Dense(n_h, activation='softmax', name='horizontal')(h)
    out_v = layers.Dense(n_v, activation='softmax', name='vertical')(h)
    model = models.Model(inp, [out_s, out_h, out_v])
    model.compile(
        optimizer=tf.keras.optimizers.Adam(1e-3),
        loss={
            "surface": "sparse_categorical_crossentropy",
            "horizontal": "sparse_categorical_crossentropy",
            "vertical": "sparse_categorical_crossentropy"
        },
        metrics=["accuracy"]
    )
    return model

# -------------------- ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ --------------------
def main():
    ap = argparse.ArgumentParser(description="Transformer ëª¨ë¸ í•™ìŠµ ë° LOSO í‰ê°€ ìŠ¤í¬ë¦½íŠ¸")
    ap.add_argument('--project_tag', required=True, help='í”„ë¡œì íŠ¸ ë²„ì „ íƒœê·¸')
    ap.add_argument('--build_tag', required=True, help='ë°ì´í„°ì…‹ ë¹Œë“œ ë²„ì „ íƒœê·¸')
    ap.add_argument('--epochs', type=int, default=80)
    ap.add_argument('--batch_size', type=int, default=64)
    args = ap.parse_args()

    # ê²½ë¡œ ì„¤ì •
    artifacts_root = os.path.join('artifacts', args.project_tag, args.build_tag)
    if not os.path.isdir(artifacts_root):
        raise FileNotFoundError(f"ì…ë ¥ ë°°ì—´ í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤: {artifacts_root}")

    timestamp = time.strftime('%Y%m%d_%H%M%S')
    runs_root = os.path.join('runs', args.project_tag, args.build_tag, f'transformer_{timestamp}')
    os.makedirs(runs_root, exist_ok=True)

    # ë°ì´í„° ë¡œë”©
    X, y_s, y_h, y_v, m_v, groups, meta = load_arrays(artifacts_root, args.build_tag)
    N, L, F = X.shape

    # ì „ì²´ ì‹¤í–‰ ì •ë³´ ì €ì¥ (manifest.json)
    with open(os.path.join(runs_root, 'manifest.json'), 'w', encoding='utf-8') as f:
        json.dump({
            'project_tag': args.project_tag, 'build_tag': args.build_tag, 'model_type': 'Transformer',
            'timestamp': timestamp, 'seq_len': int(L), 'feat_dim': int(F),
            'epochs': args.epochs, 'batch_size': args.batch_size,
            'artifacts_root': os.path.abspath(artifacts_root)
        }, f, ensure_ascii=False, indent=2)

    # LOSO êµì°¨ ê²€ì¦ ë£¨í”„
    for fold_i, (person, tr_idx, te_idx) in enumerate(make_loso_splits(groups), start=1):
        t_fold_start = time.time()

        fold_dir = os.path.join(runs_root, f'loso-{person}')
        for d in ['models', 'preds', 'metrics']:
            os.makedirs(os.path.join(fold_dir, d), exist_ok=True)

        print(f'\n=== FOLD {fold_i}/{len(set(groups))} | Testing on person={person} ===')

        # ë°ì´í„° ë¶„í•  ë° ë¼ë²¨ ì²˜ë¦¬
        Xtr, Xte = X[tr_idx], X[te_idx]
        ytr_s, yte_s = y_s[tr_idx], y_s[te_idx]
        ytr_h, yte_h = y_h[tr_idx], y_h[te_idx]
        ytr_v, yte_v = y_v[tr_idx], y_v[te_idx]
        mtr_v, mte_v = m_v[tr_idx], m_v[te_idx]
        ytr_v_eff = np.where(ytr_v < 0, 0, ytr_v)
        yte_v_eff = np.where(yte_v < 0, 0, yte_v)
        
        # ëª¨ë¸ ìƒì„± ë° í•™ìŠµ
        model = build_mt_transformer((L, F))
        cb = [
            tf.keras.callbacks.ModelCheckpoint(
                os.path.join(fold_dir, 'models', 'transformer_best_model.h5'),
                save_best_only=True, monitor='val_surface_accuracy', mode='max'),
            tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)
        ]
        model.fit(
            Xtr, [ytr_s, ytr_h, ytr_v_eff],
            validation_data=(Xte, [yte_s, yte_h, yte_v_eff], {"vertical": mte_v}),
            epochs=args.epochs, batch_size=args.batch_size,
            sample_weight={"surface": np.ones_like(ytr_s), "horizontal": np.ones_like(ytr_h), "vertical": mtr_v},
            callbacks=cb, verbose=2
        )

        # ì˜ˆì¸¡ ë° ê²°ê³¼ ì €ì¥
        yhat_s, yhat_h, yhat_v = model.predict(Xte, verbose=0)
        ypred_s, ypred_h, ypred_v = yhat_s.argmax(1), yhat_h.argmax(1), yhat_v.argmax(1)
        np.save(os.path.join(fold_dir, 'preds', 'y_true_surface.npy'), yte_s)
        np.save(os.path.join(fold_dir, 'preds', 'y_pred_surface.npy'), ypred_s)
        np.save(os.path.join(fold_dir, 'preds', 'y_true_horizontal.npy'), yte_h)
        np.save(os.path.join(fold_dir, 'preds', 'y_pred_horizontal.npy'), ypred_h)
        np.save(os.path.join(fold_dir, 'preds', 'y_true_vertical.npy'), yte_v)
        np.save(os.path.join(fold_dir, 'preds', 'y_pred_vertical.npy'), ypred_v)

        # ì„±ëŠ¥ ì§€í‘œ ê³„ì‚° ë° ì €ì¥
        metrics_dir = os.path.join(fold_dir, 'metrics')
        rep_s = classification_report(yte_s, ypred_s, output_dict=True, zero_division=0)
        rep_h = classification_report(yte_h, ypred_h, output_dict=True, zero_division=0)
        f1_metrics = {
            'surface': {'macro_f1': rep_s['macro avg']['f1-score']},
            'horizontal': {'macro_f1': rep_h['macro avg']['f1-score']}
        }
        if np.any(yte_v >= 0):
            mask = yte_v >= 0
            rep_v = classification_report(yte_v[mask], ypred_v[mask], output_dict=True, zero_division=0)
            f1_metrics['vertical'] = {'macro_f1': rep_v['macro avg']['f1-score']}
        
        with open(os.path.join(metrics_dir, 'f1.json'), 'w', encoding='utf-8') as f:
            json.dump(f1_metrics, f, ensure_ascii=False, indent=2)

        # Fold ì²˜ë¦¬ ì‹œê°„ ê¸°ë¡ ë° ì €ì¥
        fold_duration_sec = time.time() - t_fold_start
        with open(os.path.join(fold_dir, 'manifest.json'), 'w', encoding='utf-8') as f:
            json.dump({
                'person': person,
                'train_count': int(tr_idx.sum()),
                'test_count': int(te_idx.sum()),
                'duration_sec': fold_duration_sec
            }, f, ensure_ascii=False, indent=2)
            
        print(f"[INFO] Fold {person} complete in {fold_duration_sec:.2f}s. Val F1(surface): {f1_metrics['surface']['macro_f1']:.4f}")

    print('\nâœ… All folds finished for Transformer.')
    print(f'ğŸ“ Runs saved to: {runs_root}')

if __name__ == '__main__':
    main()